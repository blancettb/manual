{
  "name": "Event Stream has more than the recommended number of connected Kafka clients",
  "description": "Checks whether the number of connected Kafka clients exceeds the recommended maximum",
  "type": "MANUAL",
  "tags": [
    "container",
    "docker",
    "podman",
    "cpu",
    "diagnostic",
    "watsonx"
  ],
  "fields": [
    {
        "name": "content",
        "description": "Content for manual action",
        "encoding": "base64",
        "value": "
1. **Inspect Connected Clients:** First, check the number of connected clients in your Kafka cluster. You can use tools like `kafka-topics.sh` or the Kafka console to view this information. If the number of connected clients is high, consider disconnecting some clients to comply with the recommended limit.


   For example, if the recommended maximum is 5 and you have 6 connected clients, you can disconnect one client using the command `kafka-topics.sh --topic <topic> --alter --topic-config max.connections=<new_limit>` or the Kafka Console User Interface.

2. **Adjust Client Configuration:** Another solution is to adjust the client configuration in your application to match the recommended limit. This can be done by setting the `max.connections` property in your client configuration to the recommended value. For instance, if the recommended maximum is 5 and you have 6 connected clients, you can set the `max.connections` property to 5 in your client configuration.

3. **Monitor Cluster Health:** Regularly monitor the health of your Kafka cluster to ensure that it remains stable and responsive even after disconnecting or adjusting client configurations. Use tools like Prometheus or Grafana to monitor various metrics such as CPU usage, memory utilization, and network traffic.

4. **Implement Load Balancing:** Implementing a load balancer can help distribute the workload across multiple clients, reducing the number of active clients at any given time. This can help prevent overloading a single client and ensure that the overall performance of the system remains acceptable.

5. **Update Kafka Version:** If the issue persists, consider updating the Kafka version to a newer one. Some older versions may have a lower recommended client connection limit. However, keep in mind that upgrading Kafka should be done carefully, following the official upgrade guidelines provided by Confluent, the company behind Apache",
        "secured": false
    }
],
  "staticId": "containerCPUDebug",
  "metadata": {
    "ai": [
      {
        "algorithm": "watsonx",
        "events": ["kLC5kTFUUM4HiMWEkqlggo6dF-s"]
      }
    ]
  }
}